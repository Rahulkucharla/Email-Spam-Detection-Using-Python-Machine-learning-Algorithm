{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5876dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hello Everyone!In this program we are going to detect Spam emails using Machine learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4bedf90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f0f2a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#I have a dataset spam_ham_dataset,Using that dataset we are going to train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1eff66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('spam_ham_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf366139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of       Unnamed: 0 label                                               text  \\\n",
       "0            605   ham  Subject: enron methanol ; meter # : 988291\\r\\n...   \n",
       "1           2349   ham  Subject: hpl nom for january 9 , 2001\\r\\n( see...   \n",
       "2           3624   ham  Subject: neon retreat\\r\\nho ho ho , we ' re ar...   \n",
       "3           4685  spam  Subject: photoshop , windows , office . cheap ...   \n",
       "4           2030   ham  Subject: re : indian springs\\r\\nthis deal is t...   \n",
       "...          ...   ...                                                ...   \n",
       "5166        1518   ham  Subject: put the 10 on the ft\\r\\nthe transport...   \n",
       "5167         404   ham  Subject: 3 / 4 / 2000 and following noms\\r\\nhp...   \n",
       "5168        2933   ham  Subject: calpine daily gas nomination\\r\\n>\\r\\n...   \n",
       "5169        1409   ham  Subject: industrial worksheets for august 2000...   \n",
       "5170        4807  spam  Subject: important online banking alert\\r\\ndea...   \n",
       "\n",
       "      label_num  \n",
       "0             0  \n",
       "1             0  \n",
       "2             0  \n",
       "3             1  \n",
       "4             0  \n",
       "...         ...  \n",
       "5166          0  \n",
       "5167          0  \n",
       "5168          0  \n",
       "5169          0  \n",
       "5170          1  \n",
       "\n",
       "[5171 rows x 4 columns]>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#now check the contents in the data set\n",
    "df.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "642723ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5171, 4)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape #displays number of rows and columns "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c14f379c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'label', 'text', 'label_num'], dtype='object')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns #displays names of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fa35a5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here we only require text and label ,so let us remove unnamed and label_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "87fedc33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('Unnamed: 0',axis=1,inplace=True) #removing unnamed:0  column from dataset\n",
    "df.drop('label_num',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63a634ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5171, 2)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66a344bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['label', 'text'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "87d51434",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now removing punctuation,stopwords from the text\n",
    "def analysing_text(text):\n",
    "    msg_nopunc=[char for char in text if char not in string.punctuation]\n",
    "    msg_nopunc=\"\".join(msg_nopunc)\n",
    "    msg_nosw=[word for word in msg_nopunc.split() if word.lower() not in stopwords.words('English') ]\n",
    "    return msg_nosw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b8f1a7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'].head().apply(analysing_text)\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer=CountVectorizer(analyzer=analysing_text)\n",
    "message_1=vectorizer.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "446626f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 4725)\t1\n",
      "  (0, 18720)\t1\n",
      "  (0, 31024)\t1\n",
      "  (0, 31017)\t1\n",
      "  (0, 4649)\t1\n",
      "  (0, 20852)\t1\n",
      "  (0, 33195)\t1\n",
      "  (0, 21764)\t1\n",
      "  (0, 31711)\t1\n",
      "  (0, 2170)\t1\n",
      "  (0, 1665)\t1\n",
      "  (0, 11)\t1\n",
      "  (0, 36658)\t1\n",
      "  (0, 20741)\t1\n",
      "  (0, 15292)\t1\n",
      "  (0, 37205)\t1\n",
      "  (0, 15235)\t1\n",
      "  (0, 36028)\t1\n",
      "  (0, 34458)\t1\n",
      "  (0, 36288)\t1\n",
      "  (0, 15137)\t2\n",
      "  (0, 47829)\t1\n",
      "  (0, 36724)\t1\n",
      "  (0, 50110)\t1\n",
      "  (0, 38632)\t1\n",
      "  :\t:\n",
      "  (5170, 13620)\t1\n",
      "  (5170, 47161)\t1\n",
      "  (5170, 38564)\t1\n",
      "  (5170, 46786)\t1\n",
      "  (5170, 38480)\t4\n",
      "  (5170, 24458)\t1\n",
      "  (5170, 25893)\t1\n",
      "  (5170, 19862)\t1\n",
      "  (5170, 13260)\t1\n",
      "  (5170, 20444)\t1\n",
      "  (5170, 48158)\t1\n",
      "  (5170, 13896)\t1\n",
      "  (5170, 30857)\t1\n",
      "  (5170, 26420)\t1\n",
      "  (5170, 43882)\t1\n",
      "  (5170, 40265)\t1\n",
      "  (5170, 13301)\t2\n",
      "  (5170, 13500)\t1\n",
      "  (5170, 25012)\t1\n",
      "  (5170, 38932)\t1\n",
      "  (5170, 21156)\t1\n",
      "  (5170, 25957)\t1\n",
      "  (5170, 12516)\t3\n",
      "  (5170, 26074)\t1\n",
      "  (5170, 11992)\t1\n"
     ]
    }
   ],
   "source": [
    "print(message_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6e53bc86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(message_1,df['label'],random_state=0,test_size=0.25)\n",
    "#here we are dividing 25per data into test data and 75 into training data\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model=MultinomialNB()\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7473fb8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "a=model.predict(x_train)\n",
    "b=model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6b7ce8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for training data 0.9865910263022176\n",
      "Accuracy for testing data 0.9767981438515081\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy for training data\",accuracy_score(y_train,a))\n",
    "print(\"Accuracy for testing data\",accuracy_score(y_test,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a502f74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for training data\n",
      " [[2729   20]\n",
      " [  32 1097]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix for training data\\n\",confusion_matrix(y_train,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "08aa381b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix for testing data\n",
      " [[906  17]\n",
      " [ 13 357]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Confusion matrix for testing data\\n\",confusion_matrix(y_test,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b019d310",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e4cf3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
